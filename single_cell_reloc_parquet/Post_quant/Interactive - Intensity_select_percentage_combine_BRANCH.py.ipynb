{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to Microfluidics_Pipe_highest (Python 3.8.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import date\n",
    "import os\n",
    "import psutil as p\n",
    "import math\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "import single_cell_reloc_parquet.global_functions.global_variables as gv\n",
    "from single_cell_reloc_parquet.Post_quant.abundance_genBckgrnd import Abundance_log_manager\n",
    "# from tqdm import tqdm\n",
    "\n",
    "#. This version was derived from the quick versions found in 'current' which is no longer current\n",
    "#! Quite a bit of stuff was removed from this version. The most recent version before this was the quick version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_Chamber_index(post_quant_root, percentile):\n",
    "\tpost_qunat_folder_percentile = f\"{percentile}th_percentile\" #* There is no need to account for dates, as this will be within a dated post_quant folder\n",
    "\tfull_path = os.path.join(os.path.join(post_quant_root, post_qunat_folder_percentile))\n",
    "\n",
    "\tyear = str(datetime.today().year)\n",
    "\tdef f_chamber(col):\n",
    "\t\ts = col.find(\"_Col\")+1\n",
    "\t\te = col.find(\"_\" + year)\n",
    "\t\tChamber = col[s:e]\n",
    "\t\treturn(Chamber)\n",
    "\n",
    "\tdef run_perc(path): #* This will give the percentage that that it was run for. Folder names can be variable but shoudl have 'th' immediately following the percentage number\n",
    "\t\tstart = path.find(\"th\") - 2\n",
    "\t\tend = path.find(\"th\")\n",
    "\t\t#* This could be changed to just path[0:2]\n",
    "\t\treturn(path[start:end])\n",
    "\n",
    "\tif os.path.exists(full_path) == True:\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tt = 0\n",
    "\t\twhile t == 0:\n",
    "\t\t\tpost_qunat_folder_percentile = input(f'No folder for {percentile}th percentile found at {full_path}. Please input folder name relative to {post_quant_root}')\n",
    "\t\t\tfull_path = os.path.join(os.path.join(post_quant_root, post_qunat_folder_percentile))\n",
    "\t\t\tif os.path.exists == True:\n",
    "\t\t\t\tt = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\tChamber_index_temp = []\n",
    "\tcount = 0\n",
    "\tfor root, dirs, files in os.walk(full_path):\n",
    "\t\tfor name in files:\n",
    "\t\t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "\t\t\t\tif name.endswith(\"index.parquet\"):\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tPath_n = f\"Path_{percentile}\"\n",
    "\t\t\t\t\tChamber_index_temp.append({Path_n: os.path.join(root, name)})\n",
    "\t\t\t\t\tcount = count + 1\n",
    "\t\t\t\t\tprint(count, end=\"\\r\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t\tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "\tChamber_index_temp = pd.DataFrame(Chamber_index_temp)\n",
    "\tChamber_index_temp[\"Chamber\"] = pd.Series(Chamber_index_temp.iloc[:,0]).apply(f_chamber)\n",
    "\tChamber_index_temp[\"Percent_run\"] = pd.Series(Chamber_index_temp.iloc[:,0]).apply(run_perc)\n",
    "\tChamber_index_temp = pd.DataFrame(Chamber_index_temp)\n",
    "\treturn(Chamber_index_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #, Non-recursively import all the chamber values and join into 95th and 99th percentile tables\n",
    "# Chamber_index = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_99))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index.append({'Path': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_95))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index.append({'Path': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "\n",
    "# Chamber_index = pd.DataFrame(Chamber_index)\n",
    "\n",
    "\n",
    "# def f_chamber(col):\n",
    "# \ts = col.find(\"_Col\")+1\n",
    "# \te = col.find(\"_\" + year)\n",
    "# \tChamber = col[s:e]\n",
    "# \treturn(Chamber)\n",
    "\n",
    "# def run_perc(path): #* This will give the percentage that that it was run for. Folder names can be variable but shoudl have 'th' immediately following the percentage number\n",
    "# \tstart = path.find(\"th\") - 2\n",
    "# \tend = path.find(\"th\")\n",
    "# \treturn(path[start:end])\n",
    "\n",
    "# Chamber_index[\"Chamber\"] = pd.Series(Chamber_index.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index[\"Percent_run\"] = pd.Series(Chamber_index.iloc[:,0]).apply(run_perc) #*Extract the run perctage from the path. The folder will contain \"xxth\"\n",
    "# Chamber_index.to_parquet(f\"Chamber_index_combined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, NEW version of Abundance genration.\n",
    "\n",
    "# def Abundance_calc_manager(local_prot_df:pd.DataFrame): #* The abundacne could be incorporated in the post-quant function, but it could slow down. It also makes the process less modular and therefore makes timing of computer location a restraint\n",
    "# \t#, Calculate the abundance for every cell at every timepoint. This is done with such density so that associations can be made to the current abundance and the Loc_score\n",
    "# \tlocal_prot_df[\"Abundance\"] = pd.Series(local_prot_df[\"factor_median_OBJ_GFP\"]).apply(lambda x: math.log(x)) #* Log transform absorbance values in a rough metric of molecules per cell. Not true measure because cannot related to baselenine dataset\n",
    "# \t#* purposely overwrit the old version. Because the dataframes are quite large, it is excessive to keep the unmodified df in memory for a couple non-mutative lines\n",
    "# \t#? Perfroming with the lambda function might be slightly faster because the function does not need to be declared for each core/run\n",
    "\n",
    "# \tgroup_prot_frame = local_prot_df.groupby([\"Protein\", \"Frame\"]) #. This may need to be changed to jsut regular \"Frame\"\n",
    "\n",
    "# \t# #* This seems like a good plac to grab the z_scores for the Loc_score and Abundance\n",
    "# \tlocal_prot_df[\"z_score_Loc\"] = group_prot_frame[\"Loc_score\"].transform(stats.zscore)\n",
    "# \tlocal_prot_df[\"z_score_Abund\"] = group_prot_frame[\"Abundance\"].transform(stats.zscore)\n",
    "# \treturn(local_prot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, This should be called after var_Chamber_index()\n",
    "def Tag_percentage_run(r: int, percentile:int): #* This version should run faster than previous and be more stable\n",
    "\trow = Chamber_index.iloc[r] #* interate into the colum list\n",
    "\n",
    "\t#. Instead of consulting the information table again, which would have to open a file, open the the lower percentile and if that is correct continue on\n",
    "\tpercentile_x = row[f\"Path_{percentile}\"]\n",
    "\tif os.path.exists(percentile_x) == True:\n",
    "\t\tpass\n",
    "\telse: #* A bit of error handling because the shift from pd.DataFrame to series or element can be unpredictable\n",
    "\t\tpercentile_x = percentile_x[0]\n",
    "\t\tif os.path.exists == False:\n",
    "\t\t\treturn(f\"Could not find a path for {r}\")\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tpercentile_x_file = pd.read_parquet(percentile_x)\n",
    "\tcol_proteins = percentile_x_file.Protein.unique()\n",
    "\n",
    "\tfail = []\n",
    "\tfor prot in col_proteins:\n",
    "\t\ttry:\n",
    "\t\t\tselected = percentage_to_use_lib.loc[prot, \"Selected_series\"]\n",
    "\t\t\tif selected == percentile:\n",
    "\t\t\t\tprot_df = percentile_x_file.loc[percentile_x_file['Protein'] == prot].copy()\n",
    "\t\t\telse:\n",
    "\t\t\t\tprot_df_path = row[f\"Path_{selected}\"]\n",
    "\t\t\t\tif os.path.exists(prot_df_path) == True:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telse: #* A bit of error handling because the shift from pd.DataFrame to series or element can be unpredictable\n",
    "\t\t\t\t\tprot_df_path = prot_df_path[0]\n",
    "\t\t\t\t\tif os.path.exists == False:\n",
    "\t\t\t\t\t\treturn(f\"Could not find a path for {r}\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\tprot_df = pd.read_parquet(prot_df_path)\n",
    "\t\t\t\tprot_df = prot_df.loc[prot_df['Protein']== prot]\n",
    "\n",
    "\t\t\t#Todo: change the below to proper name instead of the aliase given in the if '__main__'\n",
    "\t\t\tprot_df = Abundance_calc_manager(local_prot_df=prot_df)\n",
    "\t\t\tprot_df.to_parquet(f'{prot}_selected.parquet') #* This is just to keep track that the abundance has not been attached yet. Can be easily renamed with batch_rename\n",
    "\t\texcept KeyError:\n",
    "\t\t\tfail.append(f\"KeyError on {prot}\")\n",
    "\t\t\tcontinue\n",
    "\t\texcept OSError:\n",
    "\t\t\tfail.append(f\"KeyError on {prot}\")\n",
    "\treturn(fail)\n",
    "\t# \tpath = row[\"Path\"]\n",
    "\t# \tpercent = int(row[\"Percent_run\"])\n",
    "\n",
    "\t# \ttemp_df = pd.read_parquet(path)\n",
    "\n",
    "\t# \tproteins = temp_df[\"Protein\"].unique()\n",
    "\n",
    "\t# \ttry:\n",
    "\t# \t\tprotein_one = proteins[0]\n",
    "\t# \t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_one) & (percentage_to_use_lib[\"Selected_series\"] == percent)]) >0:\n",
    "\t# \t\t\tprot_one_df = temp_df.loc[temp_df[\"Protein\"] == protein_one]\n",
    "\n",
    "\t# \t\t\tprot_one_df.to_parquet(f\"{protein_one}.parquet\")\n",
    "\t# \t\telse:\n",
    "\t# \t\t\tpass\n",
    "\t# \texcept Exception as e:\n",
    "\t# \t\treturn(e, f\"{path}\")\n",
    "\n",
    "\t# \ttry:\n",
    "\t# \t\tprotein_two = proteins[1]\n",
    "\t# \t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_two) & (percentage_to_use_lib[\"Selected_series\"] == percent)])>0:\n",
    "\t# \t\t\tprot_two_df.to_parquet(f\"{protein_two}.parquet\")\n",
    "\n",
    "\t# \t\t\tprot_two_df = temp_df.loc[temp_df[\"Protein\"] == protein_two]\n",
    "\t# \t\telse:\n",
    "\t# \t\t\tpass\n",
    "\t# \texcept Exception as e:\n",
    "\t# \t\treturn(e, f\"{path}\")\n",
    "\n",
    "\t# \treturn(f\"{path} complete\")\n",
    "\t# except Exception as e:\n",
    "\t# \treturn(e, f\"{path}\")\n",
    "\n",
    "# def Tag_percentage_run(r):\n",
    "# \ttry:\n",
    "# \t\trow = Chamber_index.loc[r] #* For list of chamber values\n",
    "# \t\tpath = row[\"Path\"]\n",
    "# \t\tpercent = int(row[\"Percent_run\"])\n",
    "\n",
    "# \t\ttemp_df = pd.read_parquet(path)\n",
    "\n",
    "# \t\tproteins = temp_df[\"Protein\"].unique()\n",
    "\n",
    "# \t\ttry:\n",
    "# \t\t\tprotein_one = proteins[0]\n",
    "# \t\t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_one) & (percentage_to_use_lib[\"Selected_series\"] == percent)]) >0:\n",
    "# \t\t\t\tprot_one_df = temp_df.loc[temp_df[\"Protein\"] == protein_one]\n",
    "\n",
    "# \t\t\t\tprot_one_df.to_parquet(f\"{protein_one}.parquet\")\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tpass\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\treturn(e, f\"{path}\")\n",
    "\n",
    "# \t\ttry:\n",
    "# \t\t\tprotein_two = proteins[1]\n",
    "# \t\t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_two) & (percentage_to_use_lib[\"Selected_series\"] == percent)])>0:\n",
    "# \t\t\t\tprot_two_df.to_parquet(f\"{protein_two}.parquet\")\n",
    "\n",
    "# \t\t\t\tprot_two_df = temp_df.loc[temp_df[\"Protein\"] == protein_two]\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tpass\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\treturn(e, f\"{path}\")\n",
    "\n",
    "# \t\treturn(f\"{path} complete\")\n",
    "# \texcept Exception as e:\n",
    "# \t\treturn(e, f\"{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamber_index_95 = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_95))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index_95.append({'Path_95': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# Chamber_index_95 = pd.DataFrame(Chamber_index_95)\n",
    "# Chamber_index_95[\"Chamber\"] = pd.Series(Chamber_index_95.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index_95[\"Percent_run\"] = pd.Series(Chamber_index_95.iloc[:,0]).apply(run_perc)\n",
    "\n",
    "# Chamber_index_99 = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_99))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index_99.append({'Path_99': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# Chamber_index_99 = pd.DataFrame(Chamber_index_99)\n",
    "# Chamber_index_99[\"Chamber\"] = pd.Series(Chamber_index_99.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index_99[\"Percent_run\"] = pd.Series(Chamber_index_99.iloc[:,0]).apply(run_perc)\n",
    "\n",
    "# Chamber_index = pd.merge(Chamber_index_95,Chamber_index_99, left_on = 'Chamber', right_on = 'Chamber', how = 'outside')\n",
    "# Chamber_index.to_parquet(f\"Chamber_index_combined.parquet\")\n",
    "# #############################################>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'ni'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pcnba\\Grant Brown's Lab Dropbox\\Peter Bartlett\\Peter Bartlett Data\\Code\\single_cell_reloc\\single_cell_reloc_parquet\\Post_quant\\Intensity_select_percentage_combine.py\u001b[0m in \u001b[0;36mline 31\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=311'>312</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_str_number\u001b[39m(str_number):\u001b[39m#* this is needed right now but will be fixed in next version when switch to xxth_percentile\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=312'>313</a>\u001b[0m \t\u001b[39m# if str_number == 'ninetynine':\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=313'>314</a>\u001b[0m \t\u001b[39m# \treturn(99)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=314'>315</a>\u001b[0m \t\u001b[39m# if str_number == 'ninetyfive':\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=315'>316</a>\u001b[0m \t\u001b[39m# \treturn(95)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=316'>317</a>\u001b[0m \t\u001b[39m#. Corrected below\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=317'>318</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m(\u001b[39mint\u001b[39m(str_number[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]))\n\u001b[1;32m---> <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=319'>320</a>\u001b[0m percentage_to_use_lib[\u001b[39m\"\u001b[39m\u001b[39mSelected_series\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mSeries(percentage_to_use_lib[\u001b[39m\"\u001b[39;49m\u001b[39mSelected_series\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39;49mapply(conv_str_number)\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=320'>321</a>\u001b[0m percentage_to_use_lib\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mProtein\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=321'>322</a>\u001b[0m percentage_to_use_lib\u001b[39m.\u001b[39mto_parquet(\u001b[39m'\u001b[39m\u001b[39mpercentage_to_use_lib.parquet\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4660'>4661</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4661'>4662</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4662'>4663</a>\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4665'>4666</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4666'>4667</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4667'>4668</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4668'>4669</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4669'>4670</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4768'>4769</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4769'>4770</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/series.py?line=4770'>4771</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1119'>1120</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1121'>1122</a>\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1122'>1123</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1171'>1172</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1172'>1173</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1173'>1174</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1174'>1175</a>\u001b[0m             values,\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1175'>1176</a>\u001b[0m             f,\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1176'>1177</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1177'>1178</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1179'>1180</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1180'>1181</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1181'>1182</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/pandas/core/apply.py?line=1182'>1183</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pcnba\\Grant Brown's Lab Dropbox\\Peter Bartlett\\Peter Bartlett Data\\Code\\single_cell_reloc\\single_cell_reloc_parquet\\Post_quant\\Intensity_select_percentage_combine.py\u001b[0m in \u001b[0;36mline 29\u001b[0m, in \u001b[0;36mconv_str_number\u001b[1;34m(str_number)\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=311'>312</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_str_number\u001b[39m(str_number):\u001b[39m#* this is needed right now but will be fixed in next version when switch to xxth_percentile\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=312'>313</a>\u001b[0m \t\u001b[39m# if str_number == 'ninetynine':\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=313'>314</a>\u001b[0m \t\u001b[39m# \treturn(99)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=314'>315</a>\u001b[0m \t\u001b[39m# if str_number == 'ninetyfive':\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=315'>316</a>\u001b[0m \t\u001b[39m# \treturn(95)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=316'>317</a>\u001b[0m \t\u001b[39m#. Corrected below\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=317'>318</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m(\u001b[39mint\u001b[39;49m(str_number[\u001b[39m0\u001b[39;49m:\u001b[39m2\u001b[39;49m]))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'ni'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tGlobal_variables = {'analyze': 'E:/Microfluidics/Analyze',\n",
    "\t'microfluidics_results': 'E:/Microfluidics/RESULTS',\n",
    "\t'post_path': gv.slash_switch(input(\"Path?\")), #Todo: This needs to be changed to a input call\n",
    "\t'subset': False,\n",
    "\t'subset_by': '',\n",
    "\t'subset_collection': '',\n",
    "\t'cpu_se': os.cpu_count(),\n",
    "\t'timepoint_gap': 7.5,\n",
    "\t'percentiles': [95, 99],\n",
    "\t'multiplex': True}\n",
    "\n",
    "\ttoday = str(date.today())\n",
    "\tAbundance_calc_manager = Abundance_log_manager #.Set an alternative name for the imported function. This is temporary but just to speed up before the version in this script is removed\n",
    "\n",
    "\tpost_quant_root = Global_variables['post_path']\n",
    "\tos.chdir(post_quant_root)\n",
    "\n",
    "\tpercentage_to_use = pd.read_parquet(\"Final_combined_comparison.parquet\") #* This is fine to be hard coded as it will be produced just prior with fixed name from the percentile selection script\n",
    "\tpercentage_to_use_lib = percentage_to_use.loc[:, [\"Protein\", \"Selected_series\"]] #* Get a list of which series to be used\n",
    "\n",
    "\tdef conv_str_number(str_number):#* this is needed right now but will be fixed in next version when switch to xxth_percentile\n",
    "\t\t# if str_number == 'ninetynine':\n",
    "\t\t# \treturn(99)\n",
    "\t\t# if str_number == 'ninetyfive':\n",
    "\t\t# \treturn(95)\n",
    "\t\t#. Corrected below\n",
    "\t\treturn(int(str_number[0:2]))\n",
    "\n",
    "\tpercentage_to_use_lib[\"Selected_series\"] = pd.Series(percentage_to_use_lib[\"Selected_series\"]).apply(conv_str_number)\n",
    "\tpercentage_to_use_lib.set_index('Protein', inplace= True)\n",
    "\tpercentage_to_use_lib.to_parquet('percentage_to_use_lib.parquet')\n",
    "\n",
    "\t# #* Here if the path is given explicitly, run\n",
    "\t# post_quant_sub_99 = slash_switch(input(\"Where are the 99th percentile files? Folder name\"))\n",
    "\t# post_quant_sub_95 = slash_switch(input(\"Where are the 95th percentile files? Folder name\"))\n",
    "\t# year = str(date.today().year)\n",
    "\n",
    "\tp_n = 0\n",
    "\tfor p in Global_variables['percentiles']:\n",
    "\t\tif p_n == 0: #* This first call is just to deal with the first row, so that Chamber_index does not have to be defined outside\n",
    "\t\t\tChamber_index= var_Chamber_index(post_quant_root = post_quant_root, percentile = p)\n",
    "\t\telse:\n",
    "\t\t\tChamber_index_temp = var_Chamber_index(post_quant_root = post_quant_root, percentile = p)\n",
    "\t\t\tChamber_index = pd.merge(Chamber_index, Chamber_index_temp, left_on = 'Chamber', right_on = 'Chamber', how = 'outer')\n",
    "\t\tp_n += 1\n",
    "\n",
    "\tChamber_index = Chamber_index.dropna()\n",
    "\tChamber_index.set_index('Chamber', inplace= True)\n",
    "\t# Chamber_index_na = Chamber_index.loc[~(Chamber_index.dropna())]\n",
    "\t# if len(Chamber_index_na) > 0:\n",
    "\t# \tprint(Chamber_index_na)\n",
    "\t# state = input('Continue?')\n",
    "\n",
    "\t# if state == 'y' or state == 'yes':\n",
    "\t# \tpass\n",
    "\t# else:\n",
    "\t# \tprint('Chamber index aysmetry and input cuased termination')\n",
    "\t# \texit\n",
    "\n",
    "\t#, Create folder to copy the chosen files into\n",
    "\tfolder_path = os.path.join(post_quant_root, \"Combined_by_perc\")\n",
    "\ttry:\n",
    "\t\tos.mkdir(folder_path)\n",
    "\texcept FileExistsError: #* If the folder already exists, it will not be overwritten. The exception will be caught\n",
    "\t\tpass\n",
    "\tos.chdir(folder_path) #* Set the directory to the folder path where the files will output to\n",
    "\n",
    "\ty = Parallel(n_jobs = Global_variables['cpu_se'], verbose = 100)(delayed(Tag_percentage_run)(r=ci, percentile = Global_variables['percentiles'][0]) for ci in range(len(Chamber_index)))\n",
    "\n",
    "\tprint(y)\n",
    "\tpd.Series(y).to_csv(\"output_selection.csv\")\n",
    "\n",
    "\t# try: #* This is the same except it has a different output folder name. This is kept here just to know what the previous standard was\n",
    "\t# \tnew_folder = os.join(microfluidics_results, \"Combined_results\")\n",
    "\t# \tos.mkdir(new_folder)\n",
    "\t# except FileExistsError:\n",
    "\t# \tnew_folder = os.join(microfluidics_results, \"Combined_results\")\n",
    "\t# \tpass\n",
    "\t# os.chdir(new_folder)\n",
    "\t#* Keep a version of the df just to know what files were used. This will be helpful for merging new versions\n",
    "\t# Chamber_index.to_parquet(\"Chamber_index.parquet\", index = False)\n",
    "\n",
    "\t# #, Actually copy the chosen files\n",
    "\t# y = Parallel(n_jobs=Global_variables['cpu_se'], verbose= 100)(delayed(Tag_percentage_run)(r = c) for c in Chamber_index['Chamber'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein</th>\n",
       "      <th>Percentage_reloc</th>\n",
       "      <th>Selected_ser</th>\n",
       "      <th>Percentage_reloc_less</th>\n",
       "      <th>Selected_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSP26</td>\n",
       "      <td>45.432692</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>17.173913</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSY2</td>\n",
       "      <td>42.635659</td>\n",
       "      <td>ninetyfive</td>\n",
       "      <td>19.526627</td>\n",
       "      <td>ninetyfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSE3</td>\n",
       "      <td>25.862069</td>\n",
       "      <td>ninetyfive</td>\n",
       "      <td>19.623656</td>\n",
       "      <td>ninetyfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APC4</td>\n",
       "      <td>18.965517</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>22.900763</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATC1</td>\n",
       "      <td>47.083333</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>24.858757</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>CLB3</td>\n",
       "      <td>87.359793</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>98.921484</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>CDC6</td>\n",
       "      <td>78.486647</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>98.988439</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>EDC1</td>\n",
       "      <td>85.600000</td>\n",
       "      <td>ninetyfive</td>\n",
       "      <td>99.198626</td>\n",
       "      <td>ninetyfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>LSM3d0214r1</td>\n",
       "      <td>87.252412</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>99.265066</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>ZPR1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ninetynine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ninetynine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Protein  Percentage_reloc Selected_ser  Percentage_reloc_less  \\\n",
       "0          HSP26         45.432692   ninetynine              17.173913   \n",
       "1           GSY2         42.635659   ninetyfive              19.526627   \n",
       "2           DSE3         25.862069   ninetyfive              19.623656   \n",
       "3           APC4         18.965517   ninetynine              22.900763   \n",
       "4           ATC1         47.083333   ninetynine              24.858757   \n",
       "..           ...               ...          ...                    ...   \n",
       "319         CLB3         87.359793   ninetynine              98.921484   \n",
       "320         CDC6         78.486647   ninetynine              98.988439   \n",
       "321         EDC1         85.600000   ninetyfive              99.198626   \n",
       "322  LSM3d0214r1         87.252412   ninetynine              99.265066   \n",
       "323         ZPR1        100.000000   ninetynine             100.000000   \n",
       "\n",
       "    Selected_series  \n",
       "0        ninetynine  \n",
       "1        ninetyfive  \n",
       "2        ninetyfive  \n",
       "3        ninetynine  \n",
       "4        ninetynine  \n",
       "..              ...  \n",
       "319      ninetynine  \n",
       "320      ninetynine  \n",
       "321      ninetyfive  \n",
       "322      ninetynine  \n",
       "323      ninetynine  \n",
       "\n",
       "[324 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import date\n",
    "import os\n",
    "import psutil as p\n",
    "import math\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "import single_cell_reloc_parquet.global_functions.global_variables as gv\n",
    "from single_cell_reloc_parquet.Post_quant.abundance_genBckgrnd import Abundance_log_manager\n",
    "# from tqdm import tqdm\n",
    "\n",
    "#. This version was derived from the quick versions found in 'current' which is no longer current\n",
    "#! Quite a bit of stuff was removed from this version. The most recent version before this was the quick version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_Chamber_index(post_quant_root, percentile):\n",
    "\tpost_qunat_folder_percentile = f\"{percentile}th_percentile\" #* There is no need to account for dates, as this will be within a dated post_quant folder\n",
    "\tfull_path = os.path.join(os.path.join(post_quant_root, post_qunat_folder_percentile))\n",
    "\n",
    "\tyear = str(datetime.today().year)\n",
    "\tdef f_chamber(col):\n",
    "\t\ts = col.find(\"_Col\")+1\n",
    "\t\te = col.find(\"_\" + year)\n",
    "\t\tChamber = col[s:e]\n",
    "\t\treturn(Chamber)\n",
    "\n",
    "\tdef run_perc(path): #* This will give the percentage that that it was run for. Folder names can be variable but shoudl have 'th' immediately following the percentage number\n",
    "\t\tstart = path.find(\"th\") - 2\n",
    "\t\tend = path.find(\"th\")\n",
    "\t\t#* This could be changed to just path[0:2]\n",
    "\t\treturn(path[start:end])\n",
    "\n",
    "\tif os.path.exists(full_path) == True:\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tt = 0\n",
    "\t\twhile t == 0:\n",
    "\t\t\tpost_qunat_folder_percentile = input(f'No folder for {percentile}th percentile found at {full_path}. Please input folder name relative to {post_quant_root}')\n",
    "\t\t\tfull_path = os.path.join(os.path.join(post_quant_root, post_qunat_folder_percentile))\n",
    "\t\t\tif os.path.exists == True:\n",
    "\t\t\t\tt = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\tChamber_index_temp = []\n",
    "\tcount = 0\n",
    "\tfor root, dirs, files in os.walk(full_path):\n",
    "\t\tfor name in files:\n",
    "\t\t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "\t\t\t\tif name.endswith(\"index.parquet\"):\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tPath_n = f\"Path_{percentile}\"\n",
    "\t\t\t\t\tChamber_index_temp.append({Path_n: os.path.join(root, name)})\n",
    "\t\t\t\t\tcount = count + 1\n",
    "\t\t\t\t\tprint(count, end=\"\\r\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t\tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "\tChamber_index_temp = pd.DataFrame(Chamber_index_temp)\n",
    "\tChamber_index_temp[\"Chamber\"] = pd.Series(Chamber_index_temp.iloc[:,0]).apply(f_chamber)\n",
    "\tChamber_index_temp[\"Percent_run\"] = pd.Series(Chamber_index_temp.iloc[:,0]).apply(run_perc)\n",
    "\tChamber_index_temp = pd.DataFrame(Chamber_index_temp)\n",
    "\treturn(Chamber_index_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #, Non-recursively import all the chamber values and join into 95th and 99th percentile tables\n",
    "# Chamber_index = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_99))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index.append({'Path': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_95))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index.append({'Path': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "\n",
    "# Chamber_index = pd.DataFrame(Chamber_index)\n",
    "\n",
    "\n",
    "# def f_chamber(col):\n",
    "# \ts = col.find(\"_Col\")+1\n",
    "# \te = col.find(\"_\" + year)\n",
    "# \tChamber = col[s:e]\n",
    "# \treturn(Chamber)\n",
    "\n",
    "# def run_perc(path): #* This will give the percentage that that it was run for. Folder names can be variable but shoudl have 'th' immediately following the percentage number\n",
    "# \tstart = path.find(\"th\") - 2\n",
    "# \tend = path.find(\"th\")\n",
    "# \treturn(path[start:end])\n",
    "\n",
    "# Chamber_index[\"Chamber\"] = pd.Series(Chamber_index.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index[\"Percent_run\"] = pd.Series(Chamber_index.iloc[:,0]).apply(run_perc) #*Extract the run perctage from the path. The folder will contain \"xxth\"\n",
    "# Chamber_index.to_parquet(f\"Chamber_index_combined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, NEW version of Abundance genration.\n",
    "\n",
    "# def Abundance_calc_manager(local_prot_df:pd.DataFrame): #* The abundacne could be incorporated in the post-quant function, but it could slow down. It also makes the process less modular and therefore makes timing of computer location a restraint\n",
    "# \t#, Calculate the abundance for every cell at every timepoint. This is done with such density so that associations can be made to the current abundance and the Loc_score\n",
    "# \tlocal_prot_df[\"Abundance\"] = pd.Series(local_prot_df[\"factor_median_OBJ_GFP\"]).apply(lambda x: math.log(x)) #* Log transform absorbance values in a rough metric of molecules per cell. Not true measure because cannot related to baselenine dataset\n",
    "# \t#* purposely overwrit the old version. Because the dataframes are quite large, it is excessive to keep the unmodified df in memory for a couple non-mutative lines\n",
    "# \t#? Perfroming with the lambda function might be slightly faster because the function does not need to be declared for each core/run\n",
    "\n",
    "# \tgroup_prot_frame = local_prot_df.groupby([\"Protein\", \"Frame\"]) #. This may need to be changed to jsut regular \"Frame\"\n",
    "\n",
    "# \t# #* This seems like a good plac to grab the z_scores for the Loc_score and Abundance\n",
    "# \tlocal_prot_df[\"z_score_Loc\"] = group_prot_frame[\"Loc_score\"].transform(stats.zscore)\n",
    "# \tlocal_prot_df[\"z_score_Abund\"] = group_prot_frame[\"Abundance\"].transform(stats.zscore)\n",
    "# \treturn(local_prot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, This should be called after var_Chamber_index()\n",
    "def Tag_percentage_run(r: int, percentile:int): #* This version should run faster than previous and be more stable\n",
    "\trow = Chamber_index.iloc[r] #* interate into the colum list\n",
    "\n",
    "\t#. Instead of consulting the information table again, which would have to open a file, open the the lower percentile and if that is correct continue on\n",
    "\tpercentile_x = row[f\"Path_{percentile}\"]\n",
    "\tif os.path.exists(percentile_x) == True:\n",
    "\t\tpass\n",
    "\telse: #* A bit of error handling because the shift from pd.DataFrame to series or element can be unpredictable\n",
    "\t\tpercentile_x = percentile_x[0]\n",
    "\t\tif os.path.exists == False:\n",
    "\t\t\treturn(f\"Could not find a path for {r}\")\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tpercentile_x_file = pd.read_parquet(percentile_x)\n",
    "\tcol_proteins = percentile_x_file.Protein.unique()\n",
    "\n",
    "\tfail = []\n",
    "\tfor prot in col_proteins:\n",
    "\t\ttry:\n",
    "\t\t\tselected = percentage_to_use_lib.loc[prot, \"Selected_series\"]\n",
    "\t\t\tif selected == percentile:\n",
    "\t\t\t\tprot_df = percentile_x_file.loc[percentile_x_file['Protein'] == prot].copy()\n",
    "\t\t\telse:\n",
    "\t\t\t\tprot_df_path = row[f\"Path_{selected}\"]\n",
    "\t\t\t\tif os.path.exists(prot_df_path) == True:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telse: #* A bit of error handling because the shift from pd.DataFrame to series or element can be unpredictable\n",
    "\t\t\t\t\tprot_df_path = prot_df_path[0]\n",
    "\t\t\t\t\tif os.path.exists == False:\n",
    "\t\t\t\t\t\treturn(f\"Could not find a path for {r}\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\tprot_df = pd.read_parquet(prot_df_path)\n",
    "\t\t\t\tprot_df = prot_df.loc[prot_df['Protein']== prot]\n",
    "\n",
    "\t\t\t#Todo: change the below to proper name instead of the aliase given in the if '__main__'\n",
    "\t\t\tprot_df = Abundance_calc_manager(local_prot_df=prot_df)\n",
    "\t\t\tprot_df.to_parquet(f'{prot}_selected.parquet') #* This is just to keep track that the abundance has not been attached yet. Can be easily renamed with batch_rename\n",
    "\t\texcept KeyError:\n",
    "\t\t\tfail.append(f\"KeyError on {prot}\")\n",
    "\t\t\tcontinue\n",
    "\t\texcept OSError:\n",
    "\t\t\tfail.append(f\"KeyError on {prot}\")\n",
    "\treturn(fail)\n",
    "\t# \tpath = row[\"Path\"]\n",
    "\t# \tpercent = int(row[\"Percent_run\"])\n",
    "\n",
    "\t# \ttemp_df = pd.read_parquet(path)\n",
    "\n",
    "\t# \tproteins = temp_df[\"Protein\"].unique()\n",
    "\n",
    "\t# \ttry:\n",
    "\t# \t\tprotein_one = proteins[0]\n",
    "\t# \t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_one) & (percentage_to_use_lib[\"Selected_series\"] == percent)]) >0:\n",
    "\t# \t\t\tprot_one_df = temp_df.loc[temp_df[\"Protein\"] == protein_one]\n",
    "\n",
    "\t# \t\t\tprot_one_df.to_parquet(f\"{protein_one}.parquet\")\n",
    "\t# \t\telse:\n",
    "\t# \t\t\tpass\n",
    "\t# \texcept Exception as e:\n",
    "\t# \t\treturn(e, f\"{path}\")\n",
    "\n",
    "\t# \ttry:\n",
    "\t# \t\tprotein_two = proteins[1]\n",
    "\t# \t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_two) & (percentage_to_use_lib[\"Selected_series\"] == percent)])>0:\n",
    "\t# \t\t\tprot_two_df.to_parquet(f\"{protein_two}.parquet\")\n",
    "\n",
    "\t# \t\t\tprot_two_df = temp_df.loc[temp_df[\"Protein\"] == protein_two]\n",
    "\t# \t\telse:\n",
    "\t# \t\t\tpass\n",
    "\t# \texcept Exception as e:\n",
    "\t# \t\treturn(e, f\"{path}\")\n",
    "\n",
    "\t# \treturn(f\"{path} complete\")\n",
    "\t# except Exception as e:\n",
    "\t# \treturn(e, f\"{path}\")\n",
    "\n",
    "# def Tag_percentage_run(r):\n",
    "# \ttry:\n",
    "# \t\trow = Chamber_index.loc[r] #* For list of chamber values\n",
    "# \t\tpath = row[\"Path\"]\n",
    "# \t\tpercent = int(row[\"Percent_run\"])\n",
    "\n",
    "# \t\ttemp_df = pd.read_parquet(path)\n",
    "\n",
    "# \t\tproteins = temp_df[\"Protein\"].unique()\n",
    "\n",
    "# \t\ttry:\n",
    "# \t\t\tprotein_one = proteins[0]\n",
    "# \t\t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_one) & (percentage_to_use_lib[\"Selected_series\"] == percent)]) >0:\n",
    "# \t\t\t\tprot_one_df = temp_df.loc[temp_df[\"Protein\"] == protein_one]\n",
    "\n",
    "# \t\t\t\tprot_one_df.to_parquet(f\"{protein_one}.parquet\")\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tpass\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\treturn(e, f\"{path}\")\n",
    "\n",
    "# \t\ttry:\n",
    "# \t\t\tprotein_two = proteins[1]\n",
    "# \t\t\tif len(percentage_to_use_lib.loc[(percentage_to_use_lib[\"Protein\"] == protein_two) & (percentage_to_use_lib[\"Selected_series\"] == percent)])>0:\n",
    "# \t\t\t\tprot_two_df.to_parquet(f\"{protein_two}.parquet\")\n",
    "\n",
    "# \t\t\t\tprot_two_df = temp_df.loc[temp_df[\"Protein\"] == protein_two]\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tpass\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\treturn(e, f\"{path}\")\n",
    "\n",
    "# \t\treturn(f\"{path} complete\")\n",
    "# \texcept Exception as e:\n",
    "# \t\treturn(e, f\"{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamber_index_95 = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_95))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index_95.append({'Path_95': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# Chamber_index_95 = pd.DataFrame(Chamber_index_95)\n",
    "# Chamber_index_95[\"Chamber\"] = pd.Series(Chamber_index_95.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index_95[\"Percent_run\"] = pd.Series(Chamber_index_95.iloc[:,0]).apply(run_perc)\n",
    "\n",
    "# Chamber_index_99 = []\n",
    "# count = 0\n",
    "# for root, dirs, files, in os.walk(os.path.join(os.path.join(post_quant_root, post_quant_sub_99))):\n",
    "# \tfor name in files:\n",
    "# \t\tif name.startswith(\"Chamber\") and name.endswith(f\".parquet\"): # fix naming\n",
    "# \t\t\tif name.endswith(\"index.parquet\"):\n",
    "# \t\t\t\tpass\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tChamber_index_99.append({'Path_99': os.path.join(root, name)})\n",
    "# \t\t\t\tcount = count + 1\n",
    "# \t\t\t\tprint(count, end=\"\\r\")\n",
    "# \t\telse:\n",
    "# \t\t\tpass\n",
    "# \tbreak #This makes the program run non recursively and not decend into daughter folders\n",
    "# Chamber_index_99 = pd.DataFrame(Chamber_index_99)\n",
    "# Chamber_index_99[\"Chamber\"] = pd.Series(Chamber_index_99.iloc[:,0]).apply(f_chamber)\n",
    "# Chamber_index_99[\"Percent_run\"] = pd.Series(Chamber_index_99.iloc[:,0]).apply(run_perc)\n",
    "\n",
    "# Chamber_index = pd.merge(Chamber_index_95,Chamber_index_99, left_on = 'Chamber', right_on = 'Chamber', how = 'outside')\n",
    "# Chamber_index.to_parquet(f\"Chamber_index_combined.parquet\")\n",
    "# #############################################>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done   3 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done   4 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done   5 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done   6 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done   7 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done   8 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  11 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  12 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  13 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  14 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  15 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  19 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  20 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  21 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  22 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  23 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  24 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  25 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  27 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  28 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  31 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  32 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  33 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  34 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  35 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  36 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  37 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done  38 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"<ipython-input-13-bfcb30f069de>\", line 40, in Tag_percentage_run\n  File \"c:\\users\\pcnba\\grant brown's lab dropbox\\peter bartlett\\peter bartlett data\\code\\single_cell_reloc\\single_cell_reloc_parquet\\Post_quant\\abundance_genBckgrnd.py\", line 42, in Abundance_log_manager\n    local_prot_df[\"log_Abundance\"] = pd.Series(local_prot_df[\"OBJFactor_lessBack\"]).apply(lambda x: math.log(x)) #* Log transform absorbance values in a rough metric of molecules per cell. Not true measure because cannot related to baselenine dataset so it is still an arbitraty unit value\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\series.py\", line 4771, in apply\n    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\apply.py\", line 1123, in apply\n    return self.apply_standard()\n  File \"c:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\pandas\\core\\apply.py\", line 1174, in apply_standard\n    mapped = lib.map_infer(\n  File \"pandas\\_libs\\lib.pyx\", line 2924, in pandas._libs.lib.map_infer\n  File \"c:\\users\\pcnba\\grant brown's lab dropbox\\peter bartlett\\peter bartlett data\\code\\single_cell_reloc\\single_cell_reloc_parquet\\Post_quant\\abundance_genBckgrnd.py\", line 42, in <lambda>\n    local_prot_df[\"log_Abundance\"] = pd.Series(local_prot_df[\"OBJFactor_lessBack\"]).apply(lambda x: math.log(x)) #* Log transform absorbance values in a rough metric of molecules per cell. Not true measure because cannot related to baselenine dataset so it is still an arbitraty unit value\nValueError: math domain error\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pcnba\\Grant Brown's Lab Dropbox\\Peter Bartlett\\Peter Bartlett Data\\Code\\single_cell_reloc\\single_cell_reloc_parquet\\Post_quant\\Intensity_select_percentage_combine.py\u001b[0m in \u001b[0;36mline 72\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=357'>358</a>\u001b[0m \t\u001b[39mpass\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=358'>359</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(folder_path) \u001b[39m#* Set the directory to the folder path where the files will output to\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=360'>361</a>\u001b[0m y \u001b[39m=\u001b[39m Parallel(n_jobs \u001b[39m=\u001b[39;49m Global_variables[\u001b[39m'\u001b[39;49m\u001b[39mcpu_se\u001b[39;49m\u001b[39m'\u001b[39;49m], verbose \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)(delayed(Tag_percentage_run)(r\u001b[39m=\u001b[39;49mci, percentile \u001b[39m=\u001b[39;49m Global_variables[\u001b[39m'\u001b[39;49m\u001b[39mpercentiles\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m]) \u001b[39mfor\u001b[39;49;00m ci \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(Chamber_index)))\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=362'>363</a>\u001b[0m \u001b[39mprint\u001b[39m(y)\n\u001b[0;32m     <a href='file:///c%3A/Users/pcnba/Grant%20Brown%27s%20Lab%20Dropbox/Peter%20Bartlett/Peter%20Bartlett%20Data/Code/single_cell_reloc/single_cell_reloc_parquet/Post_quant/Intensity_select_percentage_combine.py?line=363'>364</a>\u001b[0m pd\u001b[39m.\u001b[39mSeries(y)\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39moutput_selection.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=1094'>1095</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=1096'>1097</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=1097'>1098</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=1098'>1099</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=1099'>1100</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=972'>973</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=973'>974</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=974'>975</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=975'>976</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/parallel.py?line=976'>977</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=563'>564</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=564'>565</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=565'>566</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=566'>567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=567'>568</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\concurrent\\futures\\_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=443'>444</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=444'>445</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=445'>446</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\pcnba\\miniforge3\\envs\\Microfluidics_Pipe_highest\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=386'>387</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=387'>388</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=388'>389</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=389'>390</a>\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=390'>391</a>\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pcnba/miniforge3/envs/Microfluidics_Pipe_highest/lib/concurrent/futures/_base.py?line=391'>392</a>\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tGlobal_variables = {'analyze': 'E:/Microfluidics/Analyze',\n",
    "\t'microfluidics_results': 'E:/Microfluidics/RESULTS',\n",
    "\t'post_path': gv.slash_switch(input(\"Path?\")), #Todo: This needs to be changed to a input call\n",
    "\t'subset': False,\n",
    "\t'subset_by': '',\n",
    "\t'subset_collection': '',\n",
    "\t'cpu_se': os.cpu_count(),\n",
    "\t'timepoint_gap': 7.5,\n",
    "\t'percentiles': [95, 99],\n",
    "\t'multiplex': True}\n",
    "\n",
    "\ttoday = str(date.today())\n",
    "\tAbundance_calc_manager = Abundance_log_manager #.Set an alternative name for the imported function. This is temporary but just to speed up before the version in this script is removed\n",
    "\n",
    "\tpost_quant_root = Global_variables['post_path']\n",
    "\tos.chdir(post_quant_root)\n",
    "\n",
    "\tpercentage_to_use = pd.read_parquet(\"Final_combined_comparison.parquet\") #* This is fine to be hard coded as it will be produced just prior with fixed name from the percentile selection script\n",
    "\tpercentage_to_use_lib = percentage_to_use.loc[:, [\"Protein\", \"Selected_series\"]] #* Get a list of which series to be used\n",
    "\n",
    "\tdef conv_str_number(str_number):#* this is needed right now but will be fixed in next version when switch to xxth_percentile\n",
    "\t\t#. Corrected below\n",
    "\t\ttry:\n",
    "\t\t\treturn(int(str_number))\n",
    "\t\texcept ValueError:\n",
    "\t\t\tif str_number == 'ninetynine':\n",
    "\t\t\t\treturn(99)\n",
    "\t\t\tif str_number == 'ninetyfive':\n",
    "\t\t\t\treturn(95)\n",
    "\n",
    "\tpercentage_to_use_lib[\"Selected_series\"] = pd.Series(percentage_to_use_lib[\"Selected_series\"]).apply(conv_str_number)\n",
    "\tpercentage_to_use_lib.set_index('Protein', inplace= True)\n",
    "\tpercentage_to_use_lib.to_parquet('percentage_to_use_lib.parquet')\n",
    "\n",
    "\t# #* Here if the path is given explicitly, run\n",
    "\t# post_quant_sub_99 = slash_switch(input(\"Where are the 99th percentile files? Folder name\"))\n",
    "\t# post_quant_sub_95 = slash_switch(input(\"Where are the 95th percentile files? Folder name\"))\n",
    "\t# year = str(date.today().year)\n",
    "\n",
    "\tp_n = 0\n",
    "\tfor p in Global_variables['percentiles']:\n",
    "\t\tif p_n == 0: #* This first call is just to deal with the first row, so that Chamber_index does not have to be defined outside\n",
    "\t\t\tChamber_index= var_Chamber_index(post_quant_root = post_quant_root, percentile = p)\n",
    "\t\telse:\n",
    "\t\t\tChamber_index_temp = var_Chamber_index(post_quant_root = post_quant_root, percentile = p)\n",
    "\t\t\tChamber_index = pd.merge(Chamber_index, Chamber_index_temp, left_on = 'Chamber', right_on = 'Chamber', how = 'outer')\n",
    "\t\tp_n += 1\n",
    "\n",
    "\tChamber_index = Chamber_index.dropna()\n",
    "\tChamber_index.set_index('Chamber', inplace= True)\n",
    "\t# Chamber_index_na = Chamber_index.loc[~(Chamber_index.dropna())]\n",
    "\t# if len(Chamber_index_na) > 0:\n",
    "\t# \tprint(Chamber_index_na)\n",
    "\t# state = input('Continue?')\n",
    "\n",
    "\t# if state == 'y' or state == 'yes':\n",
    "\t# \tpass\n",
    "\t# else:\n",
    "\t# \tprint('Chamber index aysmetry and input cuased termination')\n",
    "\t# \texit\n",
    "\n",
    "\t#, Create folder to copy the chosen files into\n",
    "\tfolder_path = os.path.join(post_quant_root, \"Combined_by_perc\")\n",
    "\ttry:\n",
    "\t\tos.mkdir(folder_path)\n",
    "\texcept FileExistsError: #* If the folder already exists, it will not be overwritten. The exception will be caught\n",
    "\t\tpass\n",
    "\tos.chdir(folder_path) #* Set the directory to the folder path where the files will output to\n",
    "\n",
    "\ty = Parallel(n_jobs = Global_variables['cpu_se'], verbose = 100)(delayed(Tag_percentage_run)(r=ci, percentile = Global_variables['percentiles'][0]) for ci in range(len(Chamber_index)))\n",
    "\n",
    "\tprint(y)\n",
    "\tpd.Series(y).to_csv(\"output_selection.csv\")\n",
    "\n",
    "\t# try: #* This is the same except it has a different output folder name. This is kept here just to know what the previous standard was\n",
    "\t# \tnew_folder = os.join(microfluidics_results, \"Combined_results\")\n",
    "\t# \tos.mkdir(new_folder)\n",
    "\t# except FileExistsError:\n",
    "\t# \tnew_folder = os.join(microfluidics_results, \"Combined_results\")\n",
    "\t# \tpass\n",
    "\t# os.chdir(new_folder)\n",
    "\t#* Keep a version of the df just to know what files were used. This will be helpful for merging new versions\n",
    "\t# Chamber_index.to_parquet(\"Chamber_index.parquet\", index = False)\n",
    "\n",
    "\t# #, Actually copy the chosen files\n",
    "\t# y = Parallel(n_jobs=Global_variables['cpu_se'], verbose= 100)(delayed(Tag_percentage_run)(r = c) for c in Chamber_index['Chamber'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
